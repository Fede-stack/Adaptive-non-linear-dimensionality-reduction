{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718fbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "#from sklearn.cluster import SpectralClustering\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pytest\n",
    "from dadapy import Data\n",
    "from dadapy._utils import utils as ut\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import eigh, qr, solve, svd\n",
    "from scipy.sparse import csr_matrix, eye\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.stats import ks_2samp\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c621c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mnist_test.csv')\n",
    "X = data.iloc[:, 1:].values.astype(np.float32)\n",
    "y = data.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98306e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "id  [13.56]\n",
      "iteration  1\n",
      "id  [11.65]\n",
      "iteration  2\n",
      "id  [11.56]\n",
      "iteration  3\n",
      "id  [11.56]\n",
      "iteration  4\n",
      "id  [11.56]\n",
      "iteration  5\n",
      "id  [11.56]\n",
      "iteration  6\n",
      "id  [11.56]\n",
      "iteration  7\n",
      "id  [11.56]\n",
      "iteration  8\n",
      "id  [11.56]\n",
      "iteration  9\n",
      "id  [11.56]\n"
     ]
    }
   ],
   "source": [
    "class AdaptiveSpectralClustering:\n",
    "    def __init__(self, X, n_iter=10):\n",
    "        \"\"\"\n",
    "        Initialize the clustering class with data matrix X.\n",
    "        \n",
    "        Args:\n",
    "            X: Input data matrix of shape (n_samples, n_features)\n",
    "            n_iter: Number of iterations for ID estimation\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.n_iter = n_iter\n",
    "        self.ids = None\n",
    "        self.kstars = None\n",
    "        self.similarity_matrix = None\n",
    "        self.n_components = None\n",
    "        self.neighs_ind = None\n",
    "        \n",
    "    def return_ids_kstar_binomial(self, initial_id=None, Dthr=6.67, r='opt', verbose=True):\n",
    "        \"\"\"\n",
    "        Return the id estimates of the binomial algorithm coupled with the kstar estimation of the scale.\n",
    "        \n",
    "        Args:\n",
    "            initial_id: Initial estimate of the id (default uses 2NN)\n",
    "            Dthr: Threshold value for the kstar test\n",
    "            r: Parameter of binomial estimator, 0 < r < 1\n",
    "            verbose: Whether to print progress\n",
    "        \"\"\"\n",
    "        data = Data(self.X)\n",
    "        \n",
    "        if initial_id is None:\n",
    "            data.compute_id_2NN(algorithm='base')\n",
    "        else:\n",
    "            data.compute_distances()\n",
    "            data.set_id(initial_id)\n",
    "\n",
    "        ids = np.zeros(self.n_iter)\n",
    "        kstars = np.zeros((self.n_iter, data.N), dtype=int)\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            data.compute_kstar(Dthr)\n",
    "            if verbose:\n",
    "                print(\"iteration \", i)\n",
    "                print(\"id \", data.intrinsic_dim)\n",
    "\n",
    "            r_eff = min(0.95, 0.2032**(1./data.intrinsic_dim)) if r == 'opt' else r\n",
    "            rk = np.array([dd[data.kstar[j]] for j, dd in enumerate(data.distances)])\n",
    "            rn = rk * r_eff\n",
    "            n = np.sum([dd < rn[j] for j, dd in enumerate(data.distances)], axis=1)\n",
    "            \n",
    "            id = np.log((n.mean() - 1) / (data.kstar.mean() - 1)) / np.log(r_eff)\n",
    "            data.set_id(id)\n",
    "\n",
    "            ids[i] = id\n",
    "            kstars[i] = data.kstar\n",
    "\n",
    "        self.ids = ids\n",
    "        self.kstars = kstars[(self.n_iter - 1), :]\n",
    "        return self.ids, self.kstars\n",
    "\n",
    "    def find_Kstar_neighs(self):\n",
    "        \"\"\"Find K* nearest neighbors for each point.\"\"\"\n",
    "        nn = NearestNeighbors(n_jobs=-1)\n",
    "        nn.fit(self.X)\n",
    "\n",
    "        neighs_ind = []\n",
    "        for i, obs in enumerate(self.X):\n",
    "            distance, ind = nn.kneighbors([obs], n_neighbors=int(self.kstars[i]) + 1)\n",
    "            k_neighs = ind[0][1:]\n",
    "            neighs_ind.append(k_neighs.tolist())\n",
    "            \n",
    "        self.neighs_ind = neighs_ind\n",
    "        return self.neighs_ind\n",
    "\n",
    "    def find_components(self):\n",
    "        \"\"\"Find number of components based on intrinsic dimension.\"\"\"\n",
    "        self.n_components = int(np.round(self.ids[self.n_iter-1]))\n",
    "        return self.n_components\n",
    "\n",
    "    def create_similarity_matrix(self, use_distances=False):\n",
    "        \"\"\"\n",
    "        Create similarity matrix based on K* neighbors.\n",
    "        \n",
    "        Args:\n",
    "            use_distances: If True, use euclidean distances instead of binary weights\n",
    "        \"\"\"\n",
    "        similarity_matrix = np.zeros((self.X.shape[0], self.X.shape[0]))\n",
    "        \n",
    "        if use_distances:\n",
    "            for i in range(similarity_matrix.shape[0]):   \n",
    "                distances = [distance.euclidean(self.X[i, :], self.X[j, :]) \n",
    "                           for j in self.neighs_ind[i]]\n",
    "                similarity_matrix[i, self.neighs_ind[i]] = distances\n",
    "        else:\n",
    "            for i in range(similarity_matrix.shape[0]):\n",
    "                similarity_matrix[i, self.neighs_ind[i]] = 1.0\n",
    "        \n",
    "        self.similarity_matrix = 0.5 * (similarity_matrix + similarity_matrix.T)\n",
    "        return self.similarity_matrix\n",
    "\n",
    "    def return_clustering(self, n_clusters, use_n_components=True):\n",
    "        \"\"\"\n",
    "        Perform spectral clustering using Laplacian eigenvectors.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters: Number of clusters to create\n",
    "            use_n_components: If True, use estimated intrinsic dimension for embedding\n",
    "        \"\"\"\n",
    "        if use_n_components:\n",
    "            k = self.n_components\n",
    "        else:\n",
    "            k = n_clusters\n",
    "            \n",
    "        degree_matrix = np.diag(self.similarity_matrix.sum(axis=1))\n",
    "        laplacian_matrix = degree_matrix - self.similarity_matrix\n",
    "        eigenvalues, eigenvectors = eigh(laplacian_matrix)\n",
    "        k_eigenvectors = eigenvectors[:, :k]\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)\n",
    "        kmeans.fit(k_eigenvectors)\n",
    "        return kmeans.labels_\n",
    "\n",
    "    def return_clusters(self, n_clusters):\n",
    "        \"\"\"\n",
    "        Alternative clustering method using SpectralEmbedding.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters: Number of clusters to create\n",
    "        \"\"\"\n",
    "        se = SpectralEmbedding(n_components=12, random_state=0, affinity='precomputed')\n",
    "        embs = se.fit_transform(self.similarity_matrix)\n",
    "        \n",
    "        km = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)\n",
    "        km.fit(embs)\n",
    "        return km.labels_\n",
    "\n",
    "    def fit(self, n_clusters, use_distances=False, clustering_method='spectral'):\n",
    "        \"\"\"\n",
    "        Complete pipeline for clustering.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters: Number of clusters to create\n",
    "            use_distances: Whether to use distances in similarity matrix\n",
    "            clustering_method: 'spectral' or 'embedding' for different clustering approaches\n",
    "        \n",
    "        Returns:\n",
    "            cluster_labels: Array of cluster assignments\n",
    "        \"\"\"\n",
    "        #Compute IDs and k*\n",
    "        self.return_ids_kstar_binomial()\n",
    "        \n",
    "        #Find neighbors and create similarity matrix\n",
    "        self.find_Kstar_neighs()\n",
    "        self.create_similarity_matrix(use_distances=use_distances)\n",
    "        \n",
    "        #Determine number of components\n",
    "        self.find_components()\n",
    "        \n",
    "        if clustering_method == 'spectral':\n",
    "            return self.return_clustering(n_clusters=n_clusters)\n",
    "        else:\n",
    "            return self.return_clusters(n_clusters=n_clusters)\n",
    "\n",
    "\n",
    "\n",
    "asc = AdaptiveSpectralClustering(X, n_iter=10)\n",
    "labels = asc.fit(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b150fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5924212415290765\n",
      "(0.7246392426903074, 0.8502101624146748, 0.7824184918540871)\n"
     ]
    }
   ],
   "source": [
    "print(adjusted_rand_score(y, labels))\n",
    "print(homogeneity_completeness_v_measure(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9353af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5628851287095378\n",
      "(0.7012873812832684, 0.7223280162448155, 0.7116522114321566)\n"
     ]
    }
   ],
   "source": [
    "# Spectral Clustering Sklearn default implementation based on Nearest Neighbors approach\n",
    "\n",
    "sc = SpectralClustering(random_state=0, n_clusters = 10, affinity='nearest_neighbors')\n",
    "preds_sc = sc.fit_predict(X)\n",
    "\n",
    "print(adjusted_rand_score(y, preds_sc))\n",
    "print(homogeneity_completeness_v_measure(y, preds_sc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
