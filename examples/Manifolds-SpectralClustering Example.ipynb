{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f18893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pytest\n",
    "from dadapy import Data\n",
    "from dadapy._utils import utils as ut\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import eigh, qr, solve, svd\n",
    "from scipy.sparse import csr_matrix, eye\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.stats import ks_2samp\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import distance\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6557f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "n_osservazioni = 1700\n",
    "n_variabili = 17\n",
    "R, r = 2, 1  # Parametri per il toro\n",
    "a, b = 0.1, 0.1  # Parametri per la spirale 3D\n",
    "r_sfera = 1  # Raggio della sfera\n",
    "\n",
    "\n",
    "# Generazione del toro\n",
    "theta = np.linspace(0, 2*np.pi, n_osservazioni)\n",
    "phi = np.linspace(0, 2*np.pi, n_osservazioni)\n",
    "x_toro = (R + r * np.cos(theta)) * np.cos(phi)\n",
    "y_toro = (R + r * np.cos(theta)) * np.sin(phi)\n",
    "z_toro = r * np.sin(theta)\n",
    "toro = np.column_stack((x_toro, y_toro, z_toro))\n",
    "toro = np.hstack([toro]+[np.random.normal(0, 0.05, (n_osservazioni, 3))] + [np.random.normal(0, 0.05, (n_osservazioni, n_variabili - 3))])\n",
    "\n",
    "# Generazione della spirale 3D\n",
    "t = np.linspace(0, 20*np.pi, n_osservazioni)\n",
    "x_spirale = a * t * np.cos(t)\n",
    "y_spirale = a * t * np.sin(t)\n",
    "z_spirale = b * t\n",
    "spirale_3d = np.column_stack((x_spirale, y_spirale, z_spirale))\n",
    "spirale_3d = np.hstack([spirale_3d]+[np.random.normal(0, 0.05, (n_osservazioni, 3))] + [np.random.normal(0, 0.05, (n_osservazioni, n_variabili - 3))])\n",
    "\n",
    "np.random.seed(0)\n",
    "# Generazione della sfera\n",
    "phi = np.random.uniform(0, np.pi, n_osservazioni)\n",
    "theta = np.random.uniform(0, 2*np.pi, n_osservazioni)\n",
    "x_sfera = r_sfera * np.sin(phi) * np.cos(theta)\n",
    "y_sfera = r_sfera * np.sin(phi) * np.sin(theta)\n",
    "z_sfera = r_sfera * np.cos(phi)\n",
    "sfera = np.column_stack((x_sfera, y_sfera, z_sfera))\n",
    "sfera = np.hstack([sfera]+[np.random.normal(0, 0.05, (n_osservazioni, 3))] + [np.random.normal(0, 0.05, (n_osservazioni, n_variabili - 3))])\n",
    "\n",
    "# Unione dei manifold in un unico DataFrame\n",
    "dataframes_complessi = [pd.DataFrame(toro), pd.DataFrame(spirale_3d), pd.DataFrame(sfera)]\n",
    "X = pd.concat(dataframes_complessi, ignore_index=True).values.astype(float)\n",
    "X.shape\n",
    "\n",
    "y = np.repeat(np.arange(0, 3), n_osservazioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6182ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "id  [10.5]\n",
      "iteration  1\n",
      "id  [5.41]\n",
      "iteration  2\n",
      "id  [4.56]\n",
      "iteration  3\n",
      "id  [4.05]\n",
      "iteration  4\n",
      "id  [3.69]\n",
      "iteration  5\n",
      "id  [3.46]\n",
      "iteration  6\n",
      "id  [3.37]\n",
      "iteration  7\n",
      "id  [3.32]\n",
      "iteration  8\n",
      "id  [3.31]\n",
      "iteration  9\n",
      "id  [3.3]\n"
     ]
    }
   ],
   "source": [
    "class AdaptiveSpectralClustering:\n",
    "    def __init__(self, X, n_iter=10):\n",
    "        \"\"\"\n",
    "        Initialize the clustering class with data matrix X.\n",
    "        \n",
    "        Args:\n",
    "            X: Input data matrix of shape (n_samples, n_features)\n",
    "            n_iter: Number of iterations for ID estimation\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.n_iter = n_iter\n",
    "        self.ids = None\n",
    "        self.kstars = None\n",
    "        self.similarity_matrix = None\n",
    "        self.n_components = None\n",
    "        self.neighs_ind = None\n",
    "        \n",
    "    def return_ids_kstar_binomial(self, initial_id=None, Dthr=6.67, r='opt', verbose=True):\n",
    "        \"\"\"\n",
    "        Return the id estimates of the binomial algorithm coupled with the kstar estimation of the scale.\n",
    "        \n",
    "        Args:\n",
    "            initial_id: Initial estimate of the id (default uses 2NN)\n",
    "            Dthr: Threshold value for the kstar test\n",
    "            r: Parameter of binomial estimator, 0 < r < 1\n",
    "            verbose: Whether to print progress\n",
    "        \"\"\"\n",
    "        data = Data(self.X)\n",
    "        \n",
    "        if initial_id is None:\n",
    "            data.compute_id_2NN(algorithm='base')\n",
    "        else:\n",
    "            data.compute_distances()\n",
    "            data.set_id(initial_id)\n",
    "\n",
    "        ids = np.zeros(self.n_iter)\n",
    "        kstars = np.zeros((self.n_iter, data.N), dtype=int)\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            data.compute_kstar(Dthr)\n",
    "            if verbose:\n",
    "                print(\"iteration \", i)\n",
    "                print(\"id \", data.intrinsic_dim)\n",
    "\n",
    "            r_eff = min(0.95, 0.2032**(1./data.intrinsic_dim)) if r == 'opt' else r\n",
    "            rk = np.array([dd[data.kstar[j]] for j, dd in enumerate(data.distances)])\n",
    "            rn = rk * r_eff\n",
    "            n = np.sum([dd < rn[j] for j, dd in enumerate(data.distances)], axis=1)\n",
    "            \n",
    "            id = np.log((n.mean() - 1) / (data.kstar.mean() - 1)) / np.log(r_eff)\n",
    "            data.set_id(id)\n",
    "\n",
    "            ids[i] = id\n",
    "            kstars[i] = data.kstar\n",
    "\n",
    "        self.ids = ids\n",
    "        self.kstars = kstars[(self.n_iter - 1), :]\n",
    "        return self.ids, self.kstars\n",
    "\n",
    "    def find_Kstar_neighs(self):\n",
    "        \"\"\"Find K* nearest neighbors for each point.\"\"\"\n",
    "        nn = NearestNeighbors(n_jobs=-1)\n",
    "        nn.fit(self.X)\n",
    "\n",
    "        neighs_ind = []\n",
    "        for i, obs in enumerate(self.X):\n",
    "            distance, ind = nn.kneighbors([obs], n_neighbors=int(self.kstars[i]) + 1)\n",
    "            k_neighs = ind[0][1:]\n",
    "            neighs_ind.append(k_neighs.tolist())\n",
    "            \n",
    "        self.neighs_ind = neighs_ind\n",
    "        return self.neighs_ind\n",
    "\n",
    "    def find_components(self):\n",
    "        \"\"\"Find number of components based on intrinsic dimension.\"\"\"\n",
    "        self.n_components = int(np.round(self.ids[self.n_iter-1]))\n",
    "        return self.n_components\n",
    "\n",
    "    def create_similarity_matrix(self, use_distances=False):\n",
    "        \"\"\"\n",
    "        Create similarity matrix based on K* neighbors.\n",
    "        \n",
    "        Args:\n",
    "            use_distances: If True, use euclidean distances instead of binary weights\n",
    "        \"\"\"\n",
    "        similarity_matrix = np.zeros((self.X.shape[0], self.X.shape[0]))\n",
    "        \n",
    "        if use_distances:\n",
    "            for i in range(similarity_matrix.shape[0]):   \n",
    "                distances = [distance.euclidean(self.X[i, :], self.X[j, :]) \n",
    "                           for j in self.neighs_ind[i]]\n",
    "                similarity_matrix[i, self.neighs_ind[i]] = distances\n",
    "        else:\n",
    "            for i in range(similarity_matrix.shape[0]):\n",
    "                similarity_matrix[i, self.neighs_ind[i]] = 1.0\n",
    "        \n",
    "        self.similarity_matrix = 0.5 * (similarity_matrix + similarity_matrix.T)\n",
    "        return self.similarity_matrix\n",
    "\n",
    "    def return_clustering(self, n_clusters, use_n_components=True):\n",
    "        \"\"\"\n",
    "        Perform spectral clustering using Laplacian eigenvectors.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters: Number of clusters to create\n",
    "            use_n_components: If True, use estimated intrinsic dimension for embedding\n",
    "        \"\"\"\n",
    "        if use_n_components:\n",
    "            k = self.n_components\n",
    "        else:\n",
    "            k = n_clusters\n",
    "            \n",
    "        degree_matrix = np.diag(self.similarity_matrix.sum(axis=1))\n",
    "        laplacian_matrix = degree_matrix - self.similarity_matrix\n",
    "        eigenvalues, eigenvectors = eigh(laplacian_matrix)\n",
    "        k_eigenvectors = eigenvectors[:, :k]\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)\n",
    "        kmeans.fit(k_eigenvectors)\n",
    "        return kmeans.labels_\n",
    "\n",
    "    def return_clusters(self, n_clusters):\n",
    "        \"\"\"\n",
    "        Alternative clustering method using SpectralEmbedding.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters: Number of clusters to create\n",
    "        \"\"\"\n",
    "        se = SpectralEmbedding(n_components=3, random_state=0, affinity='precomputed')\n",
    "        embs = se.fit_transform(self.similarity_matrix)\n",
    "        \n",
    "        km = KMeans(n_clusters=n_clusters, random_state=0, n_init=10)\n",
    "        km.fit(embs)\n",
    "        return km.labels_\n",
    "\n",
    "    def fit(self, n_clusters, use_distances=False, clustering_method='spectral'):\n",
    "        \"\"\"\n",
    "        Complete pipeline for clustering.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters: Number of clusters to create\n",
    "            use_distances: Whether to use distances in similarity matrix\n",
    "            clustering_method: 'spectral' or 'embedding' for different clustering approaches\n",
    "        \n",
    "        Returns:\n",
    "            cluster_labels: Array of cluster assignments\n",
    "        \"\"\"\n",
    "        #Compute IDs and k*\n",
    "        self.return_ids_kstar_binomial()\n",
    "        \n",
    "        #Find neighbors and create similarity matrix\n",
    "        self.find_Kstar_neighs()\n",
    "        self.create_similarity_matrix(use_distances=use_distances)\n",
    "        \n",
    "        #Determine number of components\n",
    "        self.find_components()\n",
    "        \n",
    "        if clustering_method == 'spectral':\n",
    "            return self.return_clustering(n_clusters=n_clusters)\n",
    "        else:\n",
    "            return self.return_clusters(n_clusters=n_clusters)\n",
    "\n",
    "\n",
    "\n",
    "asc = AdaptiveSpectralClustering(X, n_iter=10)\n",
    "labels = asc.fit(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c3fa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688522488538607\n",
      "(0.7059516899737565, 0.7235396249489138, 0.7146374597222298)\n"
     ]
    }
   ],
   "source": [
    "print(adjusted_rand_score(y, labels))\n",
    "print(homogeneity_completeness_v_measure(y, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30646964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef958f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2626520735402502\n",
      "(0.3671484155070117, 0.5332044852557576, 0.43486322249205406)\n"
     ]
    }
   ],
   "source": [
    "# Spectral Clustering Sklearn default implementation based on Nearest Neighbors approach\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "sc = SpectralClustering(random_state=0, n_clusters = 3, affinity='nearest_neighbors')\n",
    "preds_sc = sc.fit_predict(X)\n",
    "\n",
    "print(adjusted_rand_score(y, preds_sc))\n",
    "print(homogeneity_completeness_v_measure(y, preds_sc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
