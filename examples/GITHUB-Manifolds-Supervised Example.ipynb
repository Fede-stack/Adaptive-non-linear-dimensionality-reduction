{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6654c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from AdaptiveKLLE import *\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e14b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "n_osservazioni = 1700\n",
    "n_variabili = 17\n",
    "R, r = 2, 1  \n",
    "a, b = 0.1, 0.1  \n",
    "r_sfera = 1  \n",
    "\n",
    "\n",
    "theta = np.linspace(0, 2*np.pi, n_osservazioni)\n",
    "phi = np.linspace(0, 2*np.pi, n_osservazioni)\n",
    "x_toro = (R + r * np.cos(theta)) * np.cos(phi)\n",
    "y_toro = (R + r * np.cos(theta)) * np.sin(phi)\n",
    "z_toro = r * np.sin(theta)\n",
    "toro = np.column_stack((x_toro, y_toro, z_toro))\n",
    "toro = np.hstack([toro]+[np.random.normal(0, 0.05, (n_osservazioni, 3))] + [np.random.normal(0, 0.05, (n_osservazioni, n_variabili - 3))])\n",
    "\n",
    "t = np.linspace(0, 20*np.pi, n_osservazioni)\n",
    "x_spirale = a * t * np.cos(t)\n",
    "y_spirale = a * t * np.sin(t)\n",
    "z_spirale = b * t\n",
    "spirale_3d = np.column_stack((x_spirale, y_spirale, z_spirale))\n",
    "spirale_3d = np.hstack([spirale_3d]+[np.random.normal(0, 0.05, (n_osservazioni, 3))] + [np.random.normal(0, 0.05, (n_osservazioni, n_variabili - 3))])\n",
    "\n",
    "np.random.seed(0)\n",
    "phi = np.random.uniform(0, np.pi, n_osservazioni)\n",
    "theta = np.random.uniform(0, 2*np.pi, n_osservazioni)\n",
    "x_sfera = r_sfera * np.sin(phi) * np.cos(theta)\n",
    "y_sfera = r_sfera * np.sin(phi) * np.sin(theta)\n",
    "z_sfera = r_sfera * np.cos(phi)\n",
    "sfera = np.column_stack((x_sfera, y_sfera, z_sfera))\n",
    "sfera = np.hstack([sfera]+[np.random.normal(0, 0.05, (n_osservazioni, 3))] + [np.random.normal(0, 0.05, (n_osservazioni, n_variabili - 3))])\n",
    "\n",
    "dataframes_complessi = [pd.DataFrame(toro), pd.DataFrame(spirale_3d), pd.DataFrame(sfera)]\n",
    "X = pd.concat(dataframes_complessi, ignore_index=True).values.astype(float)\n",
    "X.shape\n",
    "\n",
    "y = np.repeat(np.arange(0, 3), n_osservazioni)\n",
    "\n",
    "df_ = pd.DataFrame(np.column_stack((y, X))).sample(frac = 1, random_state = 0)\n",
    "X = df_.iloc[:, 1:].values\n",
    "y = df_.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5038bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ids_kstar_binomial(data, embeddings, initial_id=None, Dthr=6.67, r='opt', n_iter = 10):\n",
    "    if initial_id is None:\n",
    "        data.compute_id_2NN(algorithm='base')\n",
    "    else:\n",
    "        data.compute_distances()\n",
    "        data.set_id(initial_id)\n",
    "\n",
    "    ids = np.zeros(n_iter)\n",
    "    ids_err = np.zeros(n_iter)\n",
    "    kstars = np.zeros((n_iter, data.N), dtype=int)\n",
    "    log_likelihoods = np.zeros(n_iter)\n",
    "    ks_stats = np.zeros(n_iter)\n",
    "    p_values = np.zeros(n_iter)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "\n",
    "      data.compute_kstar(Dthr)\n",
    "\n",
    "      r_eff = min(0.95,0.2032**(1./data.intrinsic_dim)) if r == 'opt' else r\n",
    "      \n",
    "      rk = np.array([dd[data.kstar[j]] for j, dd in enumerate(data.distances)])\n",
    "      rn = rk * r_eff\n",
    "      n = np.sum([dd < rn[j] for j, dd in enumerate(data.distances)], axis=1)\n",
    "      \n",
    "      id = np.log((n.mean() - 1) / (data.kstar.mean() - 1)) / np.log(r_eff)\n",
    "      \n",
    "      id_err = ut._compute_binomial_cramerrao(id, data.kstar-1, r_eff, data.N)\n",
    "      \n",
    "      log_lik = ut.binomial_loglik(id, data.kstar - 1, n - 1, r_eff)\n",
    "      \n",
    "      n_model = rng.binomial(data.kstar-1, r_eff**id, size=len(n))\n",
    "      ks, pv = ks_2samp(n-1, n_model)\n",
    "      \n",
    "      data.set_id(id)\n",
    "\n",
    "      ids[i] = id\n",
    "      ids_err[i] = id_err\n",
    "      kstars[i] = data.kstar\n",
    "      log_likelihoods[i] = log_lik\n",
    "      ks_stats[i] = ks\n",
    "      p_values[i] = pv\n",
    "\n",
    "    data.intrinsic_dim = id\n",
    "    data.intrinsic_dim_err = id_err\n",
    "    data.intrinsic_dim_scale = 0.5 * (rn.mean() + rk.mean())\n",
    "\n",
    "    return ids, kstars[(n_iter - 1), :]\n",
    "\n",
    "\n",
    "def find_single_k_neighs(embeddings, index, k):\n",
    "    target_embedding = embeddings[index]\n",
    "    all_distances = np.array([distance.euclidean(target_embedding, emb) for emb in embeddings])\n",
    "\n",
    "    nearest_indices = np.argsort(all_distances)[1:k+1]  \n",
    "\n",
    "    return nearest_indices.tolist()\n",
    "\n",
    "def find_adaptive_test(id_, X_test):\n",
    "    data = Data(X_test)\n",
    "    data.compute_id_2NN(algorithm='base')\n",
    "    kstars_test = np.zeros(X_test.shape[0], dtype=int)\n",
    "    Dthr = 6.67\n",
    "    data.compute_kstar(Dthr)\n",
    "\n",
    "\n",
    "    r_eff = min(0.95,0.2032**(1./id_)) if r == 'opt' else r\n",
    "\n",
    "    rk = np.array([dd[data.kstar[j]] for j, dd in enumerate(data.distances)])\n",
    "    rn = rk * r_eff\n",
    "    n = np.sum([dd < rn[j] for j, dd in enumerate(data.distances)], axis=1)\n",
    "\n",
    "    id = np.log((n.mean() - 1) / (data.kstar.mean() - 1)) / np.log(r_eff)\n",
    "\n",
    "    id_err = ut._compute_binomial_cramerrao(id, data.kstar-1, r_eff, data.N)\n",
    "\n",
    "    log_lik = ut.binomial_loglik(id, data.kstar - 1, n - 1, r_eff)\n",
    "\n",
    "    n_model = rng.binomial(data.kstar-1, r_eff**id, size=len(n))\n",
    "    ks, pv = ks_2samp(n-1, n_model)\n",
    "    return data.kstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df114c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "id  [9.21]\n",
      "iteration  1\n",
      "id  [5.66]\n",
      "iteration  2\n",
      "id  [4.45]\n",
      "iteration  3\n",
      "id  [3.73]\n",
      "iteration  4\n",
      "id  [3.19]\n",
      "iteration  5\n",
      "id  [2.84]\n",
      "iteration  6\n",
      "id  [2.7]\n",
      "iteration  7\n",
      "id  [2.67]\n",
      "iteration  8\n",
      "id  [2.67]\n",
      "iteration  9\n",
      "id  [2.67]\n",
      "iteration  10\n",
      "id  [2.67]\n",
      "iteration  11\n",
      "id  [2.67]\n",
      "iteration  12\n",
      "id  [2.67]\n",
      "iteration  13\n",
      "id  [2.67]\n",
      "iteration  14\n",
      "id  [2.67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1700/1700 [08:35<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "id  [8.78]\n",
      "iteration  1\n",
      "id  [5.6]\n",
      "iteration  2\n",
      "id  [4.54]\n",
      "iteration  3\n",
      "id  [3.87]\n",
      "iteration  4\n",
      "id  [3.37]\n",
      "iteration  5\n",
      "id  [2.98]\n",
      "iteration  6\n",
      "id  [2.77]\n",
      "iteration  7\n",
      "id  [2.68]\n",
      "iteration  8\n",
      "id  [2.67]\n",
      "iteration  9\n",
      "id  [2.66]\n",
      "iteration  10\n",
      "id  [2.66]\n",
      "iteration  11\n",
      "id  [2.66]\n",
      "iteration  12\n",
      "id  [2.66]\n",
      "iteration  13\n",
      "id  [2.66]\n",
      "iteration  14\n",
      "id  [2.66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1700/1700 [08:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "id  [9.03]\n",
      "iteration  1\n",
      "id  [5.89]\n",
      "iteration  2\n",
      "id  [4.73]\n",
      "iteration  3\n",
      "id  [4.04]\n",
      "iteration  4\n",
      "id  [3.53]\n",
      "iteration  5\n",
      "id  [3.15]\n",
      "iteration  6\n",
      "id  [2.93]\n",
      "iteration  7\n",
      "id  [2.83]\n",
      "iteration  8\n",
      "id  [2.8]\n",
      "iteration  9\n",
      "id  [2.79]\n",
      "iteration  10\n",
      "id  [2.79]\n",
      "iteration  11\n",
      "id  [2.79]\n",
      "iteration  12\n",
      "id  [2.79]\n",
      "iteration  13\n",
      "id  [2.79]\n",
      "iteration  14\n",
      "id  [2.79]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1700/1700 [08:22<00:00,  3.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "folds = 3\n",
    "n_samples = X.shape[0]\n",
    "cv_n = n_samples // folds\n",
    "n_iter = 15\n",
    "r = 'opt'\n",
    "#id_ = 3\n",
    "\n",
    "accuracy_llestar = []\n",
    "f1_llestar = []\n",
    "accuracy_lle_no_hyper = []\n",
    "f1_lle_no_hyper = []\n",
    "accuracy_lle_comp = []\n",
    "f1_lle_comp = []\n",
    "accuracy_lle_same = []\n",
    "f1_lle_same = []\n",
    "for i in range(folds):\n",
    "    start_test = cv_n * i\n",
    "    end_test = start_test + cv_n\n",
    "\n",
    "    X_test = X[start_test:end_test, :]\n",
    "    y_test = y[start_test:end_test]\n",
    "\n",
    "    X_train = np.vstack((X[:start_test, :], X[end_test:, :]))\n",
    "    y_train = np.concatenate((y[:start_test], y[end_test:]))\n",
    "\n",
    "    k_star_lle = K_starLLE(X = X_train, initial_id = None, n_iter = n_iter)\n",
    "    Y_kstar, W, kstars = k_star_lle.calculate_embedding(initial_id=None, Dthr=6.67, r='opt')\n",
    "    id_ = k_star_lle.return_ids_kstar_binomial(verbose = False)[0][n_iter-1]\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_jobs=-1)\n",
    "    knn.fit(Y_kstar, y_train)\n",
    "    \n",
    "    W = np.zeros((X_test.shape[0], X_train.shape[0]))\n",
    "    for i in tqdm(range(X_test.shape[0])):\n",
    "    \n",
    "        new_data = np.concatenate((X_test[i, :].reshape(1, -1), X_train))\n",
    "        #print(embs.shape)\n",
    "        data = Data(new_data)\n",
    "        data.set_id(id_)\n",
    "        data.compute_id_2NN(algorithm='base')\n",
    "        data.compute_kstar(Dthr=6.67)\n",
    "        k_s = data.kstar\n",
    "        nns = find_single_k_neighs(new_data, 0, k_s[0])\n",
    "        nns = np.array(nns) - 1\n",
    "        Z = X_train[nns] - X_test[i]  \n",
    "        C = np.dot(Z, Z.T)  \n",
    "        trace = np.trace(C)\n",
    "        if trace > 0:\n",
    "            R = 1e-3 * trace\n",
    "        else:\n",
    "            R = 1e-3\n",
    "        C.flat[:: len(nns) + 1] += R\n",
    "        w = solve(C, np.ones(len(nns)), assume_a=\"pos\")  \n",
    "        W[i, nns] = w / np.sum(w)\n",
    "\n",
    "        Y_kstar_test = np.dot(W, Y_kstar)\n",
    "    \n",
    "    preds_knn = knn.predict(Y_kstar_test)\n",
    "    \n",
    "    accuracy_llestar.append(accuracy_score(y_test, preds_knn))\n",
    "    f1_llestar.append(f1_score(y_test, preds_knn, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfffdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9519607843137253\n",
      "0.9518052264235131\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracy_llestar))\n",
    "print(np.mean(f1_llestar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671edcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62681549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the Non-Adaptive version\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "folds = 3\n",
    "n_samples = X.shape[0]\n",
    "cv_n = n_samples // folds\n",
    "n_iter = 10\n",
    "r = 'opt'\n",
    "\n",
    "accuracy_llestar = []\n",
    "f1_llestar = []\n",
    "accuracy_lle_no_hyper = []\n",
    "f1_lle_no_hyper = []\n",
    "accuracy_lle_comp = []\n",
    "f1_lle_comp = []\n",
    "accuracy_lle_same = []\n",
    "f1_lle_same = []\n",
    "predictions = []\n",
    "for i in range(folds):\n",
    "    start_test = cv_n * i\n",
    "    end_test = start_test + cv_n\n",
    "\n",
    "    X_test = X[start_test:end_test, :]\n",
    "    y_test = y[start_test:end_test]\n",
    "\n",
    "    X_train = np.vstack((X[:start_test, :], X[end_test:, :]))\n",
    "    y_train = np.concatenate((y[:start_test], y[end_test:]))\n",
    "\n",
    "    ###no hyper\n",
    "    lle = LocallyLinearEmbedding(random_state=0)\n",
    "    y_lle = lle.fit_transform(X_train)\n",
    "    \n",
    "    knn_lle = KNeighborsClassifier(n_jobs=-1)\n",
    "    knn_lle.fit(y_lle, y_train)\n",
    "    \n",
    "    y_lle_test = lle.transform(X_test)\n",
    "    \n",
    "    preds_knn_lle = knn_lle.predict(y_lle_test)\n",
    "    \n",
    "    predictions.append(preds_knn_lle)\n",
    "    accuracy_lle_no_hyper.append(accuracy_score(y_test, preds_knn_lle))\n",
    "    f1_lle_no_hyper.append(f1_score(y_test, preds_knn_lle, average='weighted'))\n",
    "    \n",
    "    ### same\n",
    "    lle = LocallyLinearEmbedding(n_components=int(np.round(id_)), n_neighbors=int(np.median(kstars)), random_state=0)\n",
    "    y_lle = lle.fit_transform(X_train)\n",
    "    \n",
    "    knn_lle = KNeighborsClassifier(n_jobs=-1)\n",
    "    knn_lle.fit(y_lle, y_train)\n",
    "    \n",
    "    y_lle_test = lle.transform(X_test)\n",
    "    \n",
    "    preds_knn_lle = knn_lle.predict(y_lle_test)\n",
    "    predictions.append(preds_knn_lle)\n",
    "    \n",
    "    accuracy_lle_same.append(accuracy_score(y_test, preds_knn_lle))\n",
    "    f1_lle_same.append(f1_score(y_test, preds_knn_lle, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28a738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8713725490196077 0.9052941176470588\n",
      "0.8735548406058928 0.9048643896207628\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracy_lle_no_hyper), np.mean(accuracy_lle_same))\n",
    "print(np.mean(f1_lle_no_hyper),  np.mean(f1_lle_same))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
